import { GoogleGenAI, Type } from "@google/genai";
import { ApiConfig } from "../types";

// --- Google GenAI Implementation ---

const getGoogleClient = (apiKey: string) => {
    return new GoogleGenAI({ apiKey });
};

// --- OpenAI Compatible Implementation ---

const openAIFetch = async (url: string, apiKey: string, body: any) => {
    const headers: Record<string, string> = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
    };

    const response = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
    });

    if (!response.ok) {
        const err = await response.text();
        throw new Error(`API Error (${response.status}): ${err}`);
    }

    return response.json();
};

// --- Helpers ---

const fileToBase64 = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = () => {
            const result = reader.result as string;
            resolve(result.split(',')[1]);
        };
        reader.onerror = reject;
        reader.readAsDataURL(file);
    });
};

const extractImageFromGoogleResponse = (response: any): Blob => {
    let base64Data: string | undefined;
    if (response.candidates && response.candidates[0].content.parts) {
        for (const part of response.candidates[0].content.parts) {
            if (part.inlineData) {
                base64Data = part.inlineData.data;
                break;
            }
        }
    }
    if (!base64Data) throw new Error("No image generated by the AI.");
    return base64ToBlob(base64Data);
};

const base64ToBlob = (base64Data: string): Blob => {
    const byteCharacters = atob(base64Data);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
        byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: 'image/png' });
};

// --- Main Exported Functions ---

export const generateStickerLabels = async (imageFile: File, config: ApiConfig): Promise<string[]> => {
    const base64Data = await fileToBase64(imageFile);
    
    const systemPrompt = `
        Analyze this image, which is a 4x4 grid of stickers (16 total).
        Provide a short, descriptive filename for each sticker in the grid.
        Read the grid from left to right, top to bottom.
        The format should be kebab-case (e.g., "anime-girl-happy", "chibi-wink-peace").
        Focus on the emotion, action, or key object. Keep it under 4 words.
        Do not include file extensions.
        Return ONLY a JSON array of strings.
    `;

    // 1. Google Logic
    if (config.provider === 'google') {
        const ai = getGoogleClient(config.apiKey);
        const response = await ai.models.generateContent({
            model: config.visionModel || 'gemini-2.5-flash-latest',
            contents: {
                parts: [
                    { inlineData: { mimeType: imageFile.type, data: base64Data } },
                    { text: systemPrompt }
                ]
            },
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: { type: Type.STRING }
                }
            }
        });

        const jsonText = response.text;
        if (!jsonText) throw new Error("No data returned from AI");
        const labels = JSON.parse(jsonText);
        return Array.isArray(labels) ? labels : Array(16).fill("sticker");
    } 
    
    // 2. OpenAI Compatible Logic
    else {
        // Ensure Base URL is clean
        let baseUrl = config.baseUrl.replace(/\/+$/, '');
        if (!baseUrl) baseUrl = 'https://api.openai.com/v1';
        
        const payload = {
            model: config.visionModel || 'gpt-4o',
            messages: [
                {
                    role: "user",
                    content: [
                        { type: "text", text: systemPrompt },
                        { type: "image_url", image_url: { url: `data:${imageFile.type};base64,${base64Data}` } }
                    ]
                }
            ],
            // Some providers support json_object, some don't. We try to rely on the prompt.
            // If it's standard OpenAI, we can enforce json mode:
            // response_format: { type: "json_object" } 
        };

        const data = await openAIFetch(`${baseUrl}/chat/completions`, config.apiKey, payload);
        const content = data.choices?.[0]?.message?.content;
        
        if (!content) throw new Error("No content from OpenAI API");

        // Parse JSON from markdown code blocks if present
        let cleanContent = content.trim();
        if (cleanContent.startsWith('```json')) {
            cleanContent = cleanContent.replace(/^```json/, '').replace(/```$/, '');
        } else if (cleanContent.startsWith('```')) {
            cleanContent = cleanContent.replace(/^```/, '').replace(/```$/, '');
        }

        try {
            const labels = JSON.parse(cleanContent);
             // Handle case where it wraps in an object like { "labels": [...] }
            if (!Array.isArray(labels) && labels.labels && Array.isArray(labels.labels)) {
                return labels.labels;
            }
            return Array.isArray(labels) ? labels : Array(16).fill("sticker");
        } catch (e) {
            console.warn("Failed to parse JSON from OpenAI response", cleanContent);
            return Array(16).fill("sticker");
        }
    }
};

export const generateStickerSheet = async (
    prompt: string, 
    config: ApiConfig,
    subjectImage?: File | null, 
    styleImage?: File | null
): Promise<Blob> => {

    // Base prompt construction
    let fullPrompt = `Create a high-quality 4x4 grid sticker sheet containing 16 distinct stickers based on this description: "${prompt}". 
    The output MUST be a perfect 4x4 grid layout with clear spacing between items on a solid white background. 
    Ensure the stickers are completely separate and do not overlap the grid lines. 
    Style: Vector illustration, vibrant colors, clear outlines.`;

    // 1. Google Logic
    if (config.provider === 'google') {
        const ai = getGoogleClient(config.apiKey);
        const parts: any[] = [];

        // Attach references if available
        if (subjectImage) {
            fullPrompt += `\n\nREFERENCE INSTRUCTION: Use the attached image labeled 'Subject Reference' as the primary source for the character/object design.`;
            const base64 = await fileToBase64(subjectImage);
            parts.push({ text: "Subject Reference:" });
            parts.push({ inlineData: { mimeType: subjectImage.type, data: base64 } });
        }

        if (styleImage) {
            fullPrompt += `\n\nREFERENCE INSTRUCTION: Use the attached image labeled 'Style Reference' to determine the artistic style.`;
            const base64 = await fileToBase64(styleImage);
            parts.push({ text: "Style Reference:" });
            parts.push({ inlineData: { mimeType: styleImage.type, data: base64 } });
        }

        parts.push({ text: fullPrompt });

        const model = config.generationModel || 'gemini-2.5-flash-image';
        
        // 3-pro allows sizing config, others might not. 
        // We will be permissive and try to send imageConfig if it's a pro model, or just aspectRatio for others.
        const isPro = model.includes("pro"); 
        
        const response = await ai.models.generateContent({
            model: model,
            contents: { parts: parts },
            config: {
                imageConfig: {
                    aspectRatio: "1:1",
                    ...(isPro ? { imageSize: "4K" } : {})
                },
            },
        });
        return extractImageFromGoogleResponse(response);
    } 
    
    // 2. OpenAI Compatible Logic (DALL-E)
    else {
        // NOTE: OpenAI Image API does not support reference images in the 'images/generations' endpoint in the same way.
        // We will ignore subject/style images for this call and just use the prompt.
        
        let baseUrl = config.baseUrl.replace(/\/+$/, '');
        if (!baseUrl) baseUrl = 'https://api.openai.com/v1';

        const payload = {
            model: config.generationModel || 'dall-e-3',
            prompt: fullPrompt,
            n: 1,
            size: "1024x1024", // Standard DALL-E 3 size
            response_format: "b64_json"
        };

        const data = await openAIFetch(`${baseUrl}/images/generations`, config.apiKey, payload);
        
        const b64Json = data.data?.[0]?.b64_json;
        if (!b64Json) throw new Error("No image data returned from OpenAI API");
        
        return base64ToBlob(b64Json);
    }
};
